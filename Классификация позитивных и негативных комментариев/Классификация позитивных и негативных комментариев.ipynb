{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da9ba1ad",
   "metadata": {},
   "source": [
    "Привет еще раз!  меня зовут Люман Аблаев. Сегодня я проверю твой проект.\n",
    "<br> Дальнейшее общение будет происходить на \"ты\" если это не вызывает никаких проблем.\n",
    "<br> Желательно реагировать на каждый мой комментарий ('исправил', 'не понятно как исправить ошибку', ...)\n",
    "<br> Пожалуйста, не удаляй комментарии ревьюера, так как они повышают качество повторного ревью.\n",
    "\n",
    "Комментарии будут в <font color='green'>зеленой</font>, <font color='blue'>синей</font> или <font color='red'>красной</font> рамках:\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Если все сделано отлично\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет: </b> Если можно немного улучшить\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Ошибка:</b> Если требуются исправления. Работа не может быть принята с красными комментариями.\n",
    "</div>\n",
    "\n",
    "-------------------\n",
    "\n",
    "Будет очень хорошо, если ты будешь помечать свои действия следующим образом:\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Комментарий студента:</b> ...\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Изменения:</b> Были внесены следующие изменения ...\n",
    "</div>\n",
    "\n",
    "<font color='orange' style='font-size:24px; font-weight:bold'>Общее впечатление</font>\n",
    "* Приятно было проверять твою работу\n",
    "- Я оставил некоторые советы, обрати на них внимание. Надеюсь они будут полезными или интересными\n",
    "- Тебе удалось справиться с задачей текстов, поздравляю!\n",
    "- Отправляю проект назад, чтобы у тебя была возможность задать вопросы, если они у тебя есть. Если их нет, то можешь просто отправить проект еще раз и я его зачту\n",
    "\n",
    "\n",
    "\n",
    "<font color='green'><b>Полезные (и просто интересные) материалы:</b> \\\n",
    "Для работы с текстами используют и другие подходы. Например, сейчас активно используются RNN (LSTM) и трансформеры (BERT и другие с улицы Сезам, например, ELMO). НО! Они не являются панацеей, не всегда они нужны, так как и TF-IDF или Word2Vec + модели из классического ML тоже могут справляться. \\\n",
    "BERT тяжелый, существует много его вариаций для разных задач, есть готовые модели, есть надстройки над библиотекой transformers. Если, обучать BERT на GPU (можно в Google Colab или Kaggle), то должно быть побыстрее.\\\n",
    "https://huggingface.co/transformers/model_doc/bert.html \\\n",
    "https://t.me/renat_alimbekov \\\n",
    "https://colah.github.io/posts/2015-08-Understanding-LSTMs/ - Про LSTM \\\n",
    "https://web.stanford.edu/~jurafsky/slp3/10.pdf - про энкодер-декодер модели, этеншены\\\n",
    "https://pytorch.org/tutorials/beginner/transformer_tutorial.html - официальный гайд\n",
    "по трансформеру от создателей pytorch\\\n",
    "https://transformer.huggingface.co/ - поболтать с трансформером \\\n",
    "Библиотеки: allennlp, fairseq, transformers, tensorflow-text — множествореализованных\n",
    "методов для трансформеров методов NLP \\\n",
    "Word2Vec https://radimrehurek.com/gensim/models/word2vec.html \n",
    "\n",
    "<font color='green'>Пример BERT с GPU:\n",
    "```python\n",
    "%%time\n",
    "from tqdm import notebook\n",
    "batch_size = 2 # для примера возьмем такой батч, где будет всего две строки датасета\n",
    "embeddings = [] \n",
    "for i in notebook.tqdm(range(input_ids.shape[0] // batch_size)):\n",
    "        batch = torch.LongTensor(input_ids[batch_size*i:batch_size*(i+1)]).cuda() # закидываем тензор на GPU\n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)]).cuda()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.cuda()\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].cpu().numpy()) # перевод обратно на проц, чтобы в нумпай кинуть\n",
    "        del batch\n",
    "        del attention_mask_batch\n",
    "        del batch_embeddings\n",
    "        \n",
    "features = np.concatenate(embeddings) \n",
    "```\n",
    "Можно сделать предварительную проверку на наличие GPU.\\\n",
    "Например, так: ```device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")```\\\n",
    "Тогда вместо .cuda() нужно писать .to(device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868be036-60b6-4591-aa14-8425583e13f6",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d68192-850a-480b-9ae8-a9f28020ace7",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e97466e-da2a-4b41-a238-d1282d3f2c49",
   "metadata": {},
   "source": [
    "## Импорт необходимых библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e2795c2-e725-4b5a-8930-d492110ba3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f93ea58-63a6-4fb5-b268-0b3f6209a55e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000289cb",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Импорты и настройки на месте\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486094c5-945d-4fe0-8dc6-17a97d1eb7dc",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdd025f2-f5ec-41e1-a4f6-42ddfcbe3c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv('toxic_comments.csv')\n",
    "except:\n",
    "    df = pd.read_csv('/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82eab7bf-ce22-4d8f-864a-18e310d83389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                               text  toxic\n",
      "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
      "1           1  D'aww! He matches this background colour I'm s...      0\n",
      "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
      "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
      "4           4  You, sir, are my hero. Any chance you remember...      0\n",
      "------------------------------\n",
      "Дубликаты: 0\n",
      "------------------------------\n",
      "Пропуски: Unnamed: 0    0\n",
      "text          0\n",
      "toxic         0\n",
      "dtype: int64\n",
      "------------------------------\n",
      "Соотношение в целевом признаке: 0    0.898388\n",
      "1    0.101612\n",
      "Name: toxic, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df.head(5))\n",
    "print('-' * 30)\n",
    "print('Дубликаты:', df.duplicated().sum())\n",
    "print('-' * 30)\n",
    "print('Пропуски:', df.isna().sum())\n",
    "print('-' * 30)\n",
    "print('Соотношение в целевом признаке:', df.toxic.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5af603",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Отлично, что обнаружен дисбаланс - это очень важно в задачах калссификации\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d39c138-06bc-4652-8091-0ea410576385",
   "metadata": {},
   "source": [
    "Нужно избавиться от столбца `Unnamed`, так как данный столбец дублирует индексацию и не важен в обучении модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e627b2f-bbf5-46f9-bdb6-5acbf10834ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587a6061",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Верно, он избыточен\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ead8ff-8d71-443f-a296-7c668eb07edd",
   "metadata": {},
   "source": [
    "Лемматизируем и очистим датасет от лишних символов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "481133b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06ed7228-35be-4439-ab7f-1c66866b0eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text: str) -> str:\n",
    "    re_list = re.sub(r\"[^a-zA-Z']\", ' ', text)\n",
    "    re_list = re_list.split()\n",
    "    re_list = \" \".join(re_list)\n",
    "    return re_list\n",
    "\n",
    "m = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text: str) -> str:\n",
    "    word_list = nltk.word_tokenize(text)\n",
    "    return ' '.join([m.lemmatize(w, get_wordnet_pos(w)) for w in word_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d6f498",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<b>Совет:</b>  Для более корректной работы  WordNetLemmatizer, вместо со словом, желательно передавать его POS-тег (part of speech). https://webdevblog.ru/podhody-lemmatizacii-s-primerami-v-python/\n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dc2573",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Изменения:</b> Теперь передаю POS-тег. Спасибо!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168f954c",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "<b>Успех[2]:</b> 👍\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4defc552-2838-447e-83ec-0c09b3b61f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(clear_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d14d160-5995-41b8-b28d-4c8ee057b94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemm_text'] = df['text'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d94e484-d7aa-4e5f-847b-a941c0e4a6cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation Why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "      <td>Explanation Why the edits make under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww He matches this background colour I'm se...</td>\n",
       "      <td>0</td>\n",
       "      <td>D'aww He match this background colour I 'm see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man I'm really not trying to edit war It's...</td>\n",
       "      <td>0</td>\n",
       "      <td>Hey man I 'm really not try to edit war It 's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>More I can't make any real suggestions on impr...</td>\n",
       "      <td>0</td>\n",
       "      <td>More I ca n't make any real suggestion on impr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You sir are my hero Any chance you remember wh...</td>\n",
       "      <td>0</td>\n",
       "      <td>You sir be my hero Any chance you remember wha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159287</th>\n",
       "      <td>And for the second time of asking when your vi...</td>\n",
       "      <td>0</td>\n",
       "      <td>And for the second time of ask when your view ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159288</th>\n",
       "      <td>You should be ashamed of yourself That is a ho...</td>\n",
       "      <td>0</td>\n",
       "      <td>You should be ashamed of yourself That be a ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159289</th>\n",
       "      <td>Spitzer Umm theres no actual article for prost...</td>\n",
       "      <td>0</td>\n",
       "      <td>Spitzer Umm there no actual article for prosti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159290</th>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "      <td>And it look like it be actually you who put on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159291</th>\n",
       "      <td>And I really don't think you understand I came...</td>\n",
       "      <td>0</td>\n",
       "      <td>And I really do n't think you understand I com...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic  \\\n",
       "0       Explanation Why the edits made under my userna...      0   \n",
       "1       D'aww He matches this background colour I'm se...      0   \n",
       "2       Hey man I'm really not trying to edit war It's...      0   \n",
       "3       More I can't make any real suggestions on impr...      0   \n",
       "4       You sir are my hero Any chance you remember wh...      0   \n",
       "...                                                   ...    ...   \n",
       "159287  And for the second time of asking when your vi...      0   \n",
       "159288  You should be ashamed of yourself That is a ho...      0   \n",
       "159289  Spitzer Umm theres no actual article for prost...      0   \n",
       "159290  And it looks like it was actually you who put ...      0   \n",
       "159291  And I really don't think you understand I came...      0   \n",
       "\n",
       "                                                lemm_text  \n",
       "0       Explanation Why the edits make under my userna...  \n",
       "1       D'aww He match this background colour I 'm see...  \n",
       "2       Hey man I 'm really not try to edit war It 's ...  \n",
       "3       More I ca n't make any real suggestion on impr...  \n",
       "4       You sir be my hero Any chance you remember wha...  \n",
       "...                                                   ...  \n",
       "159287  And for the second time of ask when your view ...  \n",
       "159288  You should be ashamed of yourself That be a ho...  \n",
       "159289  Spitzer Umm there no actual article for prosti...  \n",
       "159290  And it look like it be actually you who put on...  \n",
       "159291  And I really do n't think you understand I com...  \n",
       "\n",
       "[159292 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6e5b79",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b>  Приятно видеть результаты до/после. \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000f05be-b3fc-4704-95e7-0478503ca038",
   "metadata": {},
   "source": [
    "Удалим столбец `text`, так как мы его не будем использовать в обучении моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36ed90ab-c9fe-4b99-a5c9-3385076ceb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['text'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad6715e-ee94-40b5-929c-79677820ed14",
   "metadata": {},
   "source": [
    "Создадим корпус из лемматизированных и очищенных текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a18d3ed-3855-47f9-bba0-e3ddcb1fe221",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df['lemm_text'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf6200b-4930-43a0-950f-bbd650ab494e",
   "metadata": {},
   "source": [
    "Выполним сплитование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01a9ec09-fd7a-4e51-b162-05f30e3a21b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = corpus\n",
    "target = df['toxic'].values\n",
    "\n",
    "train_features, test_features, train_target, test_target = train_test_split(features, target, test_size=0.2, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1395f2b-14af-457b-a1c4-99d8dd4ece58",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "\n",
    "count_tf_idf = TfidfVectorizer(stop_words=list(stopwords))\n",
    "train_features = count_tf_idf.fit_transform(train_features)\n",
    "test_features = count_tf_idf.transform(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7066278d",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "<b>Успех:</b> Хорошо, что векторизатор обучен только на обучающей выборке - это уменьшает переобучение \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cec369-9064-4ec2-8fac-68623354f9a2",
   "metadata": {},
   "source": [
    "**Промежуточный вывод:**\n",
    "\n",
    "- Был удалён столбец `Unnamed`, так как он дублировал индексирование датафрейма\n",
    "- Были очищены и лемматизированы данных из столбца `text`. Итоговые даннные были помещены в столбец `lemm_text`\n",
    "- Столбец `text` был удалён за ненадобностью, так как все необходимые данные хранятся в `lemm_text`\n",
    "- Данные были разделены на тренировочную и тестовую выборки\n",
    "- Тренировочные данные были векторизованы с помощью `TfidfVectorizer`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9219ce25-a3bb-43b4-952e-a81ae4fc153d",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50292db6-8227-41f7-afe8-da58b488f464",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2936c817-d975-4349-8fd7-3d222a34e087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Итоговое значение F1-score: 0.7550162516015498\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'class_weight': ['balanced'],\n",
    "    'C': [10]\n",
    "}\n",
    "\n",
    "model_lr = LogisticRegression()\n",
    "grid_lr = GridSearchCV(model_lr, params, scoring='f1', cv=3)\n",
    "grid_lr.fit(train_features, train_target)\n",
    "\n",
    "print('Итоговое значение F1-score:', grid_lr.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead857e8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет: </b>  Также напомню, что внутри кросс-валидации происходих разбиение выборки на треин и валидацию. Однако, в таком случае векторизатор обучен на всей выборке, а это не совсем корректно. Для избежания такого эффекта можно использовать <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\">пайплайн</a>.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6107d1d9-f25b-4bec-8147-43db45809eec",
   "metadata": {},
   "source": [
    "### CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c1ac9b6-bfa3-48a1-b5bc-5d322f1b07fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.4198349\ttotal: 21s\tremaining: 34m 41s\n",
      "20:\tlearn: 0.7577993\ttotal: 8m 6s\tremaining: 30m 29s\n",
      "40:\tlearn: 0.7911395\ttotal: 16m 16s\tremaining: 23m 25s\n",
      "60:\tlearn: 0.8119662\ttotal: 23m 47s\tremaining: 15m 12s\n",
      "80:\tlearn: 0.8299983\ttotal: 32m 13s\tremaining: 7m 33s\n",
      "99:\tlearn: 0.8429580\ttotal: 39m 28s\tremaining: 0us\n",
      "Итоговое значение F1-score: 0.8429579523153368\n"
     ]
    }
   ],
   "source": [
    "#train_features_cat =  train_features.toarray() \n",
    "\n",
    "model_cat = CatBoostClassifier(eval_metric='F1', iterations=100, max_depth=10, learning_rate=0.9, random_state=12345)\n",
    "model_cat.fit(train_features, train_target, verbose=20)\n",
    "\n",
    "print('Итоговое значение F1-score:', model_cat.best_score_['learn']['F1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962129c0-6e4c-477b-840c-ede3b9e0268e",
   "metadata": {},
   "source": [
    "### LightBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e67013-deda-40a5-a4a7-92556b52271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_depth': range(1, 13, 3),\n",
    "    'learning_rate': np.arange(0.1, 1.1, 0.3),\n",
    "    'n_estimators': range(51, 101, 10)\n",
    "}\n",
    "\n",
    "model_lgbm = LGBMClassifier()\n",
    "\n",
    "grid_lgbm = GridSearchCV(model_lgbm, params, cv=3, scoring='f1')\n",
    "grid_lgbm.fit(train_features, train_target)\n",
    "\n",
    "print('Итоговое значение F1-score:', grid_lgbm.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca440d6-b3c6-4034-8d7a-5eab8b9643e9",
   "metadata": {},
   "source": [
    "Систематизируем полученные данные для определения лучшей модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394f71e1-eb20-404d-ba41-434c9666aa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'LogisticRegression': grid_lr.best_score_,\n",
    "    'CatBosstClassifier': model_cat.best_score_['learn']['F1'],\n",
    "    'LightGBMClassifier': grid_lgbm.best_score_\n",
    "}\n",
    "\n",
    "df_results = pd.DataFrame(\n",
    "    data=data,\n",
    "    index=['f1_score'],\n",
    ")\n",
    "df_results.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715f0fa1-d6c5-481a-a7e9-c1bc6489fed4",
   "metadata": {},
   "source": [
    "Исходя из полученных значений на тренировочных данных, можно сделать вывод, что лучшей моделью для заказчика будет `CatBoostClassifier` с `f1-score` в **0.846685**. Проверим данную модель на тестовых данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78582e67",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Выбор модели обоснован!\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b14af4c-ae68-4381-98fb-6b3939d7de0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_cat.predict(test_features)\n",
    "print('Итоговое значение f1:', f1_score(test_target, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb96285d-923f-4ca1-b2b4-176f8abd2477",
   "metadata": {},
   "source": [
    "Значение `f1-score` на тестовых данных получилось **0.767939715704744**, что больше **0.75**, значит, условия задачи были выполнены."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d0d181",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> На тестовой выборке получено хорошее качество!\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09ca23f-0a85-49f7-94ee-3863bcff487b",
   "metadata": {},
   "source": [
    "## Итоговый вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa02520-849f-4b41-9205-385212f3cd13",
   "metadata": {},
   "source": [
    "**Предобработка данных:**\n",
    "\n",
    "- Был удалён столбец `Unnamed`, так как он дублировал индексирование датафрейма\n",
    "- Были очищены и лемматизированы данных из столбца `text`. Итоговые даннные были помещены в столбец `lemm_text`\n",
    "- Столбец `text` был удалён за ненадобностью, так как все необходимые данные хранятся в `lemm_text`\n",
    "- Данные были разделены на тренировочную и тестовую выборки\n",
    "- Тренировочные данные были векторизованы с помощью `TfidfVectorizer`\n",
    "\n",
    "**Обучение моделей:**\n",
    "- Исходя из полученных значений на тренировочных данных, можно сделать вывод, что лучшей моделью для заказчика будет `CatBoostClassifier` с `f1-score` в **0.846685**.\n",
    "- значение `f1-score` на тестовых данных модели `CatBoostClassifier` получилось **0.767939715704744**, что больше **0.75**, значит, условия задачи были выполнены."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2153ff",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Вывод составлен грамотно и структурированно!\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 2841,
    "start_time": "2023-10-20T14:24:51.893Z"
   },
   {
    "duration": 304,
    "start_time": "2023-10-20T14:24:54.737Z"
   },
   {
    "duration": 249,
    "start_time": "2023-10-20T14:24:55.043Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-20T14:24:55.294Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-20T14:24:55.295Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-20T14:24:55.296Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-20T14:24:55.308Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-20T14:24:55.309Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-20T14:24:55.311Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-20T14:24:55.311Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-20T14:24:55.312Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-20T14:24:55.314Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-20T14:24:55.315Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-20T14:24:55.316Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-20T14:24:55.317Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-20T14:24:55.318Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-20T14:24:55.319Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-20T14:24:55.320Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-20T14:24:55.321Z"
   },
   {
    "duration": 2443,
    "start_time": "2023-10-20T14:25:10.939Z"
   },
   {
    "duration": 256,
    "start_time": "2023-10-20T14:25:14.619Z"
   },
   {
    "duration": 23,
    "start_time": "2023-10-20T14:25:15.795Z"
   },
   {
    "duration": 4,
    "start_time": "2023-10-20T14:25:17.502Z"
   },
   {
    "duration": 7,
    "start_time": "2023-10-20T14:25:18.519Z"
   },
   {
    "duration": 4294,
    "start_time": "2023-10-20T14:25:21.750Z"
   },
   {
    "duration": 4,
    "start_time": "2023-10-20T14:25:30.429Z"
   },
   {
    "duration": 3707,
    "start_time": "2023-10-20T14:25:31.164Z"
   },
   {
    "duration": 647,
    "start_time": "2023-10-20T14:25:34.873Z"
   },
   {
    "duration": 291,
    "start_time": "2023-10-20T14:26:00.490Z"
   },
   {
    "duration": 673,
    "start_time": "2023-10-20T14:26:07.282Z"
   },
   {
    "duration": 5,
    "start_time": "2023-10-20T14:26:39.464Z"
   },
   {
    "duration": 1213478,
    "start_time": "2023-10-20T14:26:45.351Z"
   },
   {
    "duration": 23,
    "start_time": "2023-10-20T15:18:05.327Z"
   },
   {
    "duration": 50,
    "start_time": "2023-10-20T15:18:23.275Z"
   },
   {
    "duration": 4,
    "start_time": "2023-10-20T15:18:23.609Z"
   },
   {
    "duration": 20,
    "start_time": "2023-10-20T15:18:24.205Z"
   },
   {
    "duration": 8710,
    "start_time": "2023-10-20T15:18:25.416Z"
   },
   {
    "duration": 209801,
    "start_time": "2023-10-20T15:18:50.508Z"
   },
   {
    "duration": 2410108,
    "start_time": "2023-10-20T15:22:20.311Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
